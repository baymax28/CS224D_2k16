{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named legacy_seq2seq.python.ops.seq2seq",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-69fe100015d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# from tensorflow.models.rnn import seq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# import tensorflow.nn.seq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_seq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequence_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_loss_by_example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named legacy_seq2seq.python.ops.seq2seq"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils import calculate_perplexity, get_ptb_dataset, Vocab\n",
    "from utils import ptb_iterator, sample\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.seq2seq import sequence_loss, sequence_loss_by_example\n",
    "# from tensorflow.contrib.seq2seq.python.ops.loss import sequence_loss_by_example\n",
    "# from tensorflow.models.rnn import seq2seq\n",
    "# import tensorflow.nn.seq2seq\n",
    "# from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import sequence_loss, sequence_loss_by_example\n",
    "from model import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(debug=False):\n",
    "    \"\"\"Loads starter word-vectors and train/dev/test data.\"\"\"\n",
    "    vocab = Vocab()\n",
    "    vocab.construct(get_ptb_dataset('train'))\n",
    "    encoded_train = np.array(\n",
    "        [vocab.encode(word) for word in get_ptb_dataset('train')],\n",
    "        dtype=np.int32)\n",
    "    encoded_valid = np.array(\n",
    "        [vocab.encode(word) for word in get_ptb_dataset('valid')],\n",
    "        dtype=np.int32)\n",
    "    encoded_test = np.array(\n",
    "        [vocab.encode(word) for word in get_ptb_dataset('test')],\n",
    "        dtype=np.int32)\n",
    "    if debug:\n",
    "      num_debug = 1024\n",
    "      encoded_train = encoded_train[:num_debug]\n",
    "      encoded_valid = encoded_valid[:num_debug]\n",
    "      encoded_test = encoded_test[:num_debug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929589.0 total words with 10000 uniques\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocab()\n",
    "vocab.construct(get_ptb_dataset('train'))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<unk>',\n",
       " 1: 'aer',\n",
       " 2: 'banknote',\n",
       " 3: 'berlitz',\n",
       " 4: 'calloway',\n",
       " 5: 'centrust',\n",
       " 6: 'cluett',\n",
       " 7: 'fromstein',\n",
       " 8: 'gitano',\n",
       " 9: 'guterman',\n",
       " 10: 'hydro-quebec',\n",
       " 11: 'ipo',\n",
       " 12: 'kia',\n",
       " 13: 'memotec',\n",
       " 14: 'mlx',\n",
       " 15: 'nahb',\n",
       " 16: 'punts',\n",
       " 17: 'rake',\n",
       " 18: 'regatta',\n",
       " 19: 'rubens',\n",
       " 20: 'sim',\n",
       " 21: 'snack-food',\n",
       " 22: 'ssangyong',\n",
       " 23: 'swapo',\n",
       " 24: 'wachter',\n",
       " 25: '<eos>',\n",
       " 26: 'pierre',\n",
       " 27: 'N',\n",
       " 28: 'years',\n",
       " 29: 'old',\n",
       " 30: 'will',\n",
       " 31: 'join',\n",
       " 32: 'the',\n",
       " 33: 'board',\n",
       " 34: 'as',\n",
       " 35: 'a',\n",
       " 36: 'nonexecutive',\n",
       " 37: 'director',\n",
       " 38: 'nov.',\n",
       " 39: 'mr.',\n",
       " 40: 'is',\n",
       " 41: 'chairman',\n",
       " 42: 'of',\n",
       " 43: 'n.v.',\n",
       " 44: 'dutch',\n",
       " 45: 'publishing',\n",
       " 46: 'group',\n",
       " 47: 'rudolph',\n",
       " 48: 'and',\n",
       " 49: 'former',\n",
       " 50: 'consolidated',\n",
       " 51: 'gold',\n",
       " 52: 'fields',\n",
       " 53: 'plc',\n",
       " 54: 'was',\n",
       " 55: 'named',\n",
       " 56: 'this',\n",
       " 57: 'british',\n",
       " 58: 'industrial',\n",
       " 59: 'conglomerate',\n",
       " 60: 'form',\n",
       " 61: 'asbestos',\n",
       " 62: 'once',\n",
       " 63: 'used',\n",
       " 64: 'to',\n",
       " 65: 'make',\n",
       " 66: 'kent',\n",
       " 67: 'cigarette',\n",
       " 68: 'filters',\n",
       " 69: 'has',\n",
       " 70: 'caused',\n",
       " 71: 'high',\n",
       " 72: 'percentage',\n",
       " 73: 'cancer',\n",
       " 74: 'deaths',\n",
       " 75: 'among',\n",
       " 76: 'workers',\n",
       " 77: 'exposed',\n",
       " 78: 'it',\n",
       " 79: 'more',\n",
       " 80: 'than',\n",
       " 81: 'ago',\n",
       " 82: 'researchers',\n",
       " 83: 'reported',\n",
       " 84: 'fiber',\n",
       " 85: 'unusually',\n",
       " 86: 'enters',\n",
       " 87: 'with',\n",
       " 88: 'even',\n",
       " 89: 'brief',\n",
       " 90: 'exposures',\n",
       " 91: 'causing',\n",
       " 92: 'symptoms',\n",
       " 93: 'that',\n",
       " 94: 'show',\n",
       " 95: 'up',\n",
       " 96: 'decades',\n",
       " 97: 'later',\n",
       " 98: 'said',\n",
       " 99: 'inc.',\n",
       " 100: 'unit',\n",
       " 101: 'new',\n",
       " 102: 'york-based',\n",
       " 103: 'corp.',\n",
       " 104: 'makes',\n",
       " 105: 'cigarettes',\n",
       " 106: 'stopped',\n",
       " 107: 'using',\n",
       " 108: 'in',\n",
       " 109: 'its',\n",
       " 110: 'although',\n",
       " 111: 'preliminary',\n",
       " 112: 'findings',\n",
       " 113: 'were',\n",
       " 114: 'year',\n",
       " 115: 'latest',\n",
       " 116: 'results',\n",
       " 117: 'appear',\n",
       " 118: 'today',\n",
       " 119: \"'s\",\n",
       " 120: 'england',\n",
       " 121: 'journal',\n",
       " 122: 'medicine',\n",
       " 123: 'forum',\n",
       " 124: 'likely',\n",
       " 125: 'bring',\n",
       " 126: 'attention',\n",
       " 127: 'problem',\n",
       " 128: 'an',\n",
       " 129: 'story',\n",
       " 130: 'we',\n",
       " 131: \"'re\",\n",
       " 132: 'talking',\n",
       " 133: 'about',\n",
       " 134: 'before',\n",
       " 135: 'anyone',\n",
       " 136: 'heard',\n",
       " 137: 'having',\n",
       " 138: 'any',\n",
       " 139: 'questionable',\n",
       " 140: 'properties',\n",
       " 141: 'there',\n",
       " 142: 'no',\n",
       " 143: 'our',\n",
       " 144: 'products',\n",
       " 145: 'now',\n",
       " 146: 'neither',\n",
       " 147: 'nor',\n",
       " 148: 'who',\n",
       " 149: 'studied',\n",
       " 150: 'aware',\n",
       " 151: 'research',\n",
       " 152: 'on',\n",
       " 153: 'smokers',\n",
       " 154: 'have',\n",
       " 155: 'useful',\n",
       " 156: 'information',\n",
       " 157: 'whether',\n",
       " 158: 'users',\n",
       " 159: 'are',\n",
       " 160: 'at',\n",
       " 161: 'risk',\n",
       " 162: 'james',\n",
       " 163: 'a.',\n",
       " 164: 'boston',\n",
       " 165: 'institute',\n",
       " 166: 'dr.',\n",
       " 167: 'led',\n",
       " 168: 'team',\n",
       " 169: 'from',\n",
       " 170: 'national',\n",
       " 171: 'medical',\n",
       " 172: 'schools',\n",
       " 173: 'harvard',\n",
       " 174: 'university',\n",
       " 175: 'spokeswoman',\n",
       " 176: 'very',\n",
       " 177: 'modest',\n",
       " 178: 'amounts',\n",
       " 179: 'making',\n",
       " 180: 'paper',\n",
       " 181: 'for',\n",
       " 182: 'early',\n",
       " 183: '1950s',\n",
       " 184: 'replaced',\n",
       " 185: 'different',\n",
       " 186: 'type',\n",
       " 187: 'billion',\n",
       " 188: 'sold',\n",
       " 189: 'company',\n",
       " 190: 'men',\n",
       " 191: 'worked',\n",
       " 192: 'closely',\n",
       " 193: 'substance',\n",
       " 194: 'died',\n",
       " 195: 'three',\n",
       " 196: 'times',\n",
       " 197: 'expected',\n",
       " 198: 'number',\n",
       " 199: 'four',\n",
       " 200: 'five',\n",
       " 201: 'surviving',\n",
       " 202: 'diseases',\n",
       " 203: 'including',\n",
       " 204: 'recently',\n",
       " 205: 'total',\n",
       " 206: 'malignant',\n",
       " 207: 'lung',\n",
       " 208: 'far',\n",
       " 209: 'higher',\n",
       " 210: 'rate',\n",
       " 211: 'striking',\n",
       " 212: 'finding',\n",
       " 213: 'those',\n",
       " 214: 'us',\n",
       " 215: 'study',\n",
       " 216: 'west',\n",
       " 217: 'mass.',\n",
       " 218: 'factory',\n",
       " 219: 'appears',\n",
       " 220: 'be',\n",
       " 221: 'highest',\n",
       " 222: 'western',\n",
       " 223: 'industrialized',\n",
       " 224: 'countries',\n",
       " 225: 'he',\n",
       " 226: 'plant',\n",
       " 227: 'which',\n",
       " 228: 'owned',\n",
       " 229: 'by',\n",
       " 230: '&',\n",
       " 231: 'co.',\n",
       " 232: 'under',\n",
       " 233: 'contract',\n",
       " 234: 'probably',\n",
       " 235: 'support',\n",
       " 236: 'argue',\n",
       " 237: 'u.s.',\n",
       " 238: 'should',\n",
       " 239: 'regulate',\n",
       " 240: 'class',\n",
       " 241: 'common',\n",
       " 242: 'kind',\n",
       " 243: 'found',\n",
       " 244: 'most',\n",
       " 245: 'other',\n",
       " 246: 'buildings',\n",
       " 247: 'one',\n",
       " 248: 'few',\n",
       " 249: 'nations',\n",
       " 250: 'does',\n",
       " 251: \"n't\",\n",
       " 252: 'standard',\n",
       " 253: 'regulation',\n",
       " 254: 'smooth',\n",
       " 255: 'fibers',\n",
       " 256: 'such',\n",
       " 257: 'classified',\n",
       " 258: 'according',\n",
       " 259: 't.',\n",
       " 260: 'professor',\n",
       " 261: 'vermont',\n",
       " 262: 'college',\n",
       " 263: 'easily',\n",
       " 264: 'rejected',\n",
       " 265: 'body',\n",
       " 266: 'explained',\n",
       " 267: 'july',\n",
       " 268: 'environmental',\n",
       " 269: 'protection',\n",
       " 270: 'agency',\n",
       " 271: 'imposed',\n",
       " 272: 'gradual',\n",
       " 273: 'ban',\n",
       " 274: 'virtually',\n",
       " 275: 'all',\n",
       " 276: 'uses',\n",
       " 277: 'almost',\n",
       " 278: 'remaining',\n",
       " 279: 'outlawed',\n",
       " 280: 'made',\n",
       " 281: 'areas',\n",
       " 282: 'particularly',\n",
       " 283: 'dusty',\n",
       " 284: 'where',\n",
       " 285: 'dumped',\n",
       " 286: 'large',\n",
       " 287: 'imported',\n",
       " 288: 'material',\n",
       " 289: 'into',\n",
       " 290: 'huge',\n",
       " 291: 'poured',\n",
       " 292: 'cotton',\n",
       " 293: 'mixed',\n",
       " 294: 'dry',\n",
       " 295: 'process',\n",
       " 296: 'described',\n",
       " 297: 'clouds',\n",
       " 298: 'blue',\n",
       " 299: 'dust',\n",
       " 300: 'hung',\n",
       " 301: 'over',\n",
       " 302: 'parts',\n",
       " 303: 'though',\n",
       " 304: 'fans',\n",
       " 305: 'area',\n",
       " 306: 'question',\n",
       " 307: 'some',\n",
       " 308: 'managers',\n",
       " 309: 'contracted',\n",
       " 310: 'phillips',\n",
       " 311: 'vice',\n",
       " 312: 'president',\n",
       " 313: 'human',\n",
       " 314: 'resources',\n",
       " 315: 'but',\n",
       " 316: 'you',\n",
       " 317: 'recognize',\n",
       " 318: 'these',\n",
       " 319: 'events',\n",
       " 320: 'took',\n",
       " 321: 'place',\n",
       " 322: 'bearing',\n",
       " 323: 'work',\n",
       " 324: 'force',\n",
       " 325: 'yields',\n",
       " 326: 'money-market',\n",
       " 327: 'mutual',\n",
       " 328: 'funds',\n",
       " 329: 'continued',\n",
       " 330: 'slide',\n",
       " 331: 'amid',\n",
       " 332: 'signs',\n",
       " 333: 'portfolio',\n",
       " 334: 'expect',\n",
       " 335: 'further',\n",
       " 336: 'declines',\n",
       " 337: 'interest',\n",
       " 338: 'rates',\n",
       " 339: 'average',\n",
       " 340: 'seven-day',\n",
       " 341: 'compound',\n",
       " 342: 'yield',\n",
       " 343: 'taxable',\n",
       " 344: 'tracked',\n",
       " 345: 'money',\n",
       " 346: 'fund',\n",
       " 347: 'report',\n",
       " 348: 'eased',\n",
       " 349: 'fraction',\n",
       " 350: 'point',\n",
       " 351: 'week',\n",
       " 352: 'ended',\n",
       " 353: 'tuesday',\n",
       " 354: 'assume',\n",
       " 355: 'reinvestment',\n",
       " 356: 'dividends',\n",
       " 357: 'current',\n",
       " 358: 'continues',\n",
       " 359: 'maturity',\n",
       " 360: \"'\",\n",
       " 361: 'investments',\n",
       " 362: 'day',\n",
       " 363: 'days',\n",
       " 364: 'longest',\n",
       " 365: 'since',\n",
       " 366: 'august',\n",
       " 367: 'donoghue',\n",
       " 368: 'longer',\n",
       " 369: 'maturities',\n",
       " 370: 'thought',\n",
       " 371: 'indicate',\n",
       " 372: 'declining',\n",
       " 373: 'because',\n",
       " 374: 'they',\n",
       " 375: 'permit',\n",
       " 376: 'retain',\n",
       " 377: 'relatively',\n",
       " 378: 'period',\n",
       " 379: 'shorter',\n",
       " 380: 'considered',\n",
       " 381: 'sign',\n",
       " 382: 'rising',\n",
       " 383: 'can',\n",
       " 384: 'capture',\n",
       " 385: 'sooner',\n",
       " 386: 'open',\n",
       " 387: 'only',\n",
       " 388: 'institutions',\n",
       " 389: 'stronger',\n",
       " 390: 'indicator',\n",
       " 391: 'watch',\n",
       " 392: 'market',\n",
       " 393: 'reached',\n",
       " 394: 'nevertheless',\n",
       " 395: 'editor',\n",
       " 396: 'may',\n",
       " 397: 'again',\n",
       " 398: 'down',\n",
       " 399: 'recent',\n",
       " 400: 'rises',\n",
       " 401: 'short-term',\n",
       " 402: 'six-month',\n",
       " 403: 'treasury',\n",
       " 404: 'bills',\n",
       " 405: 'monday',\n",
       " 406: 'auction',\n",
       " 407: 'example',\n",
       " 408: 'rose',\n",
       " 409: 'despite',\n",
       " 410: 'investors',\n",
       " 411: 'continue',\n",
       " 412: 'pour',\n",
       " 413: 'cash',\n",
       " 414: 'assets',\n",
       " 415: 'grew',\n",
       " 416: '$',\n",
       " 417: 'during',\n",
       " 418: 'typically',\n",
       " 419: 'money-fund',\n",
       " 420: 'beat',\n",
       " 421: 'comparable',\n",
       " 422: 'vary',\n",
       " 423: 'go',\n",
       " 424: 'after',\n",
       " 425: 'top',\n",
       " 426: 'currently',\n",
       " 427: 'yielding',\n",
       " 428: 'well',\n",
       " 429: 'dreyfus',\n",
       " 430: 'world-wide',\n",
       " 431: 'dollar',\n",
       " 432: 'had',\n",
       " 433: 'earlier',\n",
       " 434: 'invests',\n",
       " 435: 'heavily',\n",
       " 436: 'dollar-denominated',\n",
       " 437: 'securities',\n",
       " 438: 'overseas',\n",
       " 439: 'management',\n",
       " 440: 'fees',\n",
       " 441: 'boosts',\n",
       " 442: 'simple',\n",
       " 443: '30-day',\n",
       " 444: 'fell',\n",
       " 445: 'slid',\n",
       " 446: 'j.p.',\n",
       " 447: 'grace',\n",
       " 448: 'holds',\n",
       " 449: 'elected',\n",
       " 450: 'succeeds',\n",
       " 451: 'd.',\n",
       " 452: 'formerly',\n",
       " 453: 'resigned',\n",
       " 454: 'energy',\n",
       " 455: 'seven',\n",
       " 456: 'seats',\n",
       " 457: 'pacific',\n",
       " 458: 'first',\n",
       " 459: 'financial',\n",
       " 460: 'shareholders',\n",
       " 461: 'approved',\n",
       " 462: 'acquisition',\n",
       " 463: 'royal',\n",
       " 464: 'ltd.',\n",
       " 465: 'toronto',\n",
       " 466: 'share',\n",
       " 467: 'or',\n",
       " 468: 'million',\n",
       " 469: 'thrift',\n",
       " 470: 'holding',\n",
       " 471: 'expects',\n",
       " 472: 'obtain',\n",
       " 473: 'regulatory',\n",
       " 474: 'approval',\n",
       " 475: 'complete',\n",
       " 476: 'transaction',\n",
       " 477: 'year-end',\n",
       " 478: 'international',\n",
       " 479: 'completed',\n",
       " 480: 'sale',\n",
       " 481: 'controls',\n",
       " 482: 'operations',\n",
       " 483: 's.p',\n",
       " 484: 'italian',\n",
       " 485: 'state-owned',\n",
       " 486: 'interests',\n",
       " 487: 'mechanical',\n",
       " 488: 'engineering',\n",
       " 489: 'industry',\n",
       " 490: 'based',\n",
       " 491: 'ohio',\n",
       " 492: 'computerized',\n",
       " 493: 'systems',\n",
       " 494: 'employs',\n",
       " 495: 'people',\n",
       " 496: 'annual',\n",
       " 497: 'revenue',\n",
       " 498: 'federal',\n",
       " 499: 'government',\n",
       " 500: 'suspended',\n",
       " 501: 'sales',\n",
       " 502: 'savings',\n",
       " 503: 'bonds',\n",
       " 504: 'congress',\n",
       " 505: 'lifted',\n",
       " 506: 'ceiling',\n",
       " 507: 'debt',\n",
       " 508: 'until',\n",
       " 509: 'acts',\n",
       " 510: 'authority',\n",
       " 511: 'issue',\n",
       " 512: 'obligations',\n",
       " 513: 'borrowing',\n",
       " 514: 'dropped',\n",
       " 515: 'midnight',\n",
       " 516: 'trillion',\n",
       " 517: 'legislation',\n",
       " 518: 'lift',\n",
       " 519: 'fight',\n",
       " 520: 'cutting',\n",
       " 521: 'capital-gains',\n",
       " 522: 'taxes',\n",
       " 523: 'house',\n",
       " 524: 'voted',\n",
       " 525: 'raise',\n",
       " 526: 'senate',\n",
       " 527: 'act',\n",
       " 528: 'next',\n",
       " 529: 'earliest',\n",
       " 530: 'default',\n",
       " 531: 'if',\n",
       " 532: 'then',\n",
       " 533: 'clark',\n",
       " 534: 'j.',\n",
       " 535: 'senior',\n",
       " 536: 'general',\n",
       " 537: 'manager',\n",
       " 538: 'marketing',\n",
       " 539: 'arm',\n",
       " 540: 'japanese',\n",
       " 541: 'auto',\n",
       " 542: 'maker',\n",
       " 543: 'mazda',\n",
       " 544: 'motor',\n",
       " 545: 'corp',\n",
       " 546: 'position',\n",
       " 547: 'oversee',\n",
       " 548: 'service',\n",
       " 549: 'previously',\n",
       " 550: 'chrysler',\n",
       " 551: 'division',\n",
       " 552: 'been',\n",
       " 553: 'executive',\n",
       " 554: 'when',\n",
       " 555: 'time',\n",
       " 556: 'their',\n",
       " 557: 'nation',\n",
       " 558: 'manufacturing',\n",
       " 559: 'jet',\n",
       " 560: 'off',\n",
       " 561: 'resort',\n",
       " 562: 'towns',\n",
       " 563: 'like',\n",
       " 564: 'hot',\n",
       " 565: 'springs',\n",
       " 566: 'not',\n",
       " 567: 'association',\n",
       " 568: 'manufacturers',\n",
       " 569: 'settled',\n",
       " 570: 'capital',\n",
       " 571: 'indianapolis',\n",
       " 572: 'fall',\n",
       " 573: 'meeting',\n",
       " 574: 'city',\n",
       " 575: 'decided',\n",
       " 576: 'treat',\n",
       " 577: 'guests',\n",
       " 578: 'royalty',\n",
       " 579: 'rock',\n",
       " 580: 'stars',\n",
       " 581: 'owners',\n",
       " 582: 'idea',\n",
       " 583: 'course',\n",
       " 584: 'prove',\n",
       " 585: 'corporate',\n",
       " 586: 'decision',\n",
       " 587: 'makers',\n",
       " 588: 'buckle',\n",
       " 589: 'belt',\n",
       " 590: 'so',\n",
       " 591: 'good',\n",
       " 592: 'expand',\n",
       " 593: 'receiving',\n",
       " 594: 'end',\n",
       " 595: 'message',\n",
       " 596: 'officials',\n",
       " 597: 'giants',\n",
       " 598: 'du',\n",
       " 599: 'pont',\n",
       " 600: 'along',\n",
       " 601: 'lesser',\n",
       " 602: 'steel',\n",
       " 603: 'valley',\n",
       " 604: 'queen',\n",
       " 605: 'executives',\n",
       " 606: 'joined',\n",
       " 607: 'mayor',\n",
       " 608: 'william',\n",
       " 609: 'h.',\n",
       " 610: 'iii',\n",
       " 611: 'evening',\n",
       " 612: 'guest',\n",
       " 613: 'victor',\n",
       " 614: 'champagne',\n",
       " 615: 'followed',\n",
       " 616: 'morning',\n",
       " 617: 'police',\n",
       " 618: 'wives',\n",
       " 619: 'traffic',\n",
       " 620: 'red',\n",
       " 621: 'lights',\n",
       " 622: 'governor',\n",
       " 623: 'could',\n",
       " 624: 'welcomed',\n",
       " 625: 'special',\n",
       " 626: 'buffet',\n",
       " 627: 'breakfast',\n",
       " 628: 'held',\n",
       " 629: 'museum',\n",
       " 630: 'food',\n",
       " 631: 'drinks',\n",
       " 632: 'banned',\n",
       " 633: 'everyday',\n",
       " 634: 'visitors',\n",
       " 635: 'honor',\n",
       " 636: 'out',\n",
       " 637: 'drivers',\n",
       " 638: 'crews',\n",
       " 639: 'official',\n",
       " 640: 'announcer',\n",
       " 641: 'exhibition',\n",
       " 642: 'race',\n",
       " 643: 'fortune',\n",
       " 644: 'cars',\n",
       " 645: 'pointed',\n",
       " 646: 'still',\n",
       " 647: 'space',\n",
       " 648: 'machines',\n",
       " 649: 'another',\n",
       " 650: 'sponsor',\n",
       " 651: 'name',\n",
       " 652: 'two',\n",
       " 653: 'back',\n",
       " 654: 'downtown',\n",
       " 655: 'squeezed',\n",
       " 656: 'meetings',\n",
       " 657: 'hotel',\n",
       " 658: 'buses',\n",
       " 659: 'dinner',\n",
       " 660: 'block',\n",
       " 661: 'away',\n",
       " 662: 'indiana',\n",
       " 663: 'nine',\n",
       " 664: 'hottest',\n",
       " 665: 'chefs',\n",
       " 666: 'town',\n",
       " 667: 'fed',\n",
       " 668: 'them',\n",
       " 669: 'knowing',\n",
       " 670: 'free',\n",
       " 671: 'eat',\n",
       " 672: 'gave',\n",
       " 673: 'standing',\n",
       " 674: 'say',\n",
       " 675: 'treatment',\n",
       " 676: 'return',\n",
       " 677: 'future',\n",
       " 678: 'looking',\n",
       " 679: 'forward',\n",
       " 680: 'winter',\n",
       " 681: 'february',\n",
       " 682: 'south',\n",
       " 683: 'korea',\n",
       " 684: 'registered',\n",
       " 685: 'trade',\n",
       " 686: 'deficit',\n",
       " 687: 'october',\n",
       " 688: 'reflecting',\n",
       " 689: 'country',\n",
       " 690: 'economic',\n",
       " 691: 'figures',\n",
       " 692: 'released',\n",
       " 693: 'wednesday',\n",
       " 694: 'ministry',\n",
       " 695: 'showed',\n",
       " 696: 'fifth',\n",
       " 697: 'monthly',\n",
       " 698: 'setback',\n",
       " 699: 'casting',\n",
       " 700: 'cloud',\n",
       " 701: 'economy',\n",
       " 702: 'exports',\n",
       " 703: 'stood',\n",
       " 704: 'mere',\n",
       " 705: 'increase',\n",
       " 706: 'while',\n",
       " 707: 'imports',\n",
       " 708: 'increased',\n",
       " 709: 'sharply',\n",
       " 710: 'last',\n",
       " 711: 'boom',\n",
       " 712: 'began',\n",
       " 713: 'prolonged',\n",
       " 714: 'labor',\n",
       " 715: 'disputes',\n",
       " 716: 'conflicts',\n",
       " 717: 'sluggish',\n",
       " 718: 'would',\n",
       " 719: 'remain',\n",
       " 720: 'target',\n",
       " 721: 'gloomy',\n",
       " 722: 'forecast',\n",
       " 723: 'recorded',\n",
       " 724: 'surplus',\n",
       " 725: 'january',\n",
       " 726: 'accumulated',\n",
       " 727: 'same',\n",
       " 728: 'newsweek',\n",
       " 729: 'trying',\n",
       " 730: 'keep',\n",
       " 731: 'pace',\n",
       " 732: 'rival',\n",
       " 733: 'magazine',\n",
       " 734: 'announced',\n",
       " 735: 'advertising',\n",
       " 736: 'introduce',\n",
       " 737: 'incentive',\n",
       " 738: 'plan',\n",
       " 739: 'advertisers',\n",
       " 740: 'ad',\n",
       " 741: 'washington',\n",
       " 742: 'post',\n",
       " 743: 'second',\n",
       " 744: 'offered',\n",
       " 745: 'plans',\n",
       " 746: 'give',\n",
       " 747: 'discounts',\n",
       " 748: 'maintaining',\n",
       " 749: 'increasing',\n",
       " 750: 'spending',\n",
       " 751: 'become',\n",
       " 752: 'permanent',\n",
       " 753: 'news',\n",
       " 754: 'underscore',\n",
       " 755: 'fierce',\n",
       " 756: 'competition',\n",
       " 757: 'between',\n",
       " 758: 'warner',\n",
       " 759: 'b.',\n",
       " 760: 'world',\n",
       " 761: 'alan',\n",
       " 762: 'full',\n",
       " 763: 'page',\n",
       " 764: 'cost',\n",
       " 765: 'mid-october',\n",
       " 766: 'lowered',\n",
       " 767: 'guaranteed',\n",
       " 768: 'circulation',\n",
       " 769: 'base',\n",
       " 770: 'lower',\n",
       " 771: 'effectively',\n",
       " 772: 'per',\n",
       " 773: 'subscriber',\n",
       " 774: 'costs',\n",
       " 775: 'yet',\n",
       " 776: 'announce',\n",
       " 777: 'credit',\n",
       " 778: 'credits',\n",
       " 779: 'renewal',\n",
       " 780: 'reward',\n",
       " 781: 'bonuses',\n",
       " 782: 'meet',\n",
       " 783: 'exceed',\n",
       " 784: 'long',\n",
       " 785: 'spent',\n",
       " 786: 'attempt',\n",
       " 787: 'shore',\n",
       " 788: 'decline',\n",
       " 789: 'pages',\n",
       " 790: 'months',\n",
       " 791: 'totaled',\n",
       " 792: 'drop',\n",
       " 793: 'publishers',\n",
       " 794: 'bureau',\n",
       " 795: 'what',\n",
       " 796: 'matters',\n",
       " 797: 'paying',\n",
       " 798: 'department',\n",
       " 799: 'doing',\n",
       " 800: 'fine',\n",
       " 801: 'both',\n",
       " 802: 'gaining',\n",
       " 803: 'without',\n",
       " 804: 'heavy',\n",
       " 805: 'use',\n",
       " 806: 'electronic',\n",
       " 807: 'subscribers',\n",
       " 808: 'telephones',\n",
       " 809: 'watches',\n",
       " 810: 'however',\n",
       " 811: 'none',\n",
       " 812: 'big',\n",
       " 813: 'gains',\n",
       " 814: 'audit',\n",
       " 815: 'largest',\n",
       " 816: 'decrease',\n",
       " 817: 'six',\n",
       " 818: 'flat',\n",
       " 819: 'electric',\n",
       " 820: 'system',\n",
       " 821: 'bowed',\n",
       " 822: 'bidding',\n",
       " 823: 'public',\n",
       " 824: 'hampshire',\n",
       " 825: 'saying',\n",
       " 826: 'risks',\n",
       " 827: 'too',\n",
       " 828: 'potential',\n",
       " 829: 'justify',\n",
       " 830: 'offer',\n",
       " 831: 'move',\n",
       " 832: 'leaves',\n",
       " 833: 'united',\n",
       " 834: 'illuminating',\n",
       " 835: 'northeast',\n",
       " 836: 'utilities',\n",
       " 837: 'outside',\n",
       " 838: 'bidders',\n",
       " 839: 'ps',\n",
       " 840: 'also',\n",
       " 841: 'proposed',\n",
       " 842: 'internal',\n",
       " 843: 'reorganization',\n",
       " 844: 'chapter',\n",
       " 845: 'bankruptcy',\n",
       " 846: 'proceedings',\n",
       " 847: 'independent',\n",
       " 848: 'acquire',\n",
       " 849: 'below',\n",
       " 850: 'value',\n",
       " 851: 'places',\n",
       " 852: 'bid',\n",
       " 853: 'says',\n",
       " 854: 'worth',\n",
       " 855: 'haven',\n",
       " 856: 'conn.',\n",
       " 857: 'hartford',\n",
       " 858: 'conn',\n",
       " 859: 'n.h.',\n",
       " 860: 'values',\n",
       " 861: 'john',\n",
       " 862: 'rowe',\n",
       " 863: 'chief',\n",
       " 864: 'officer',\n",
       " 865: 'equity',\n",
       " 866: 'suffer',\n",
       " 867: 'forecasts',\n",
       " 868: 'related',\n",
       " 869: 'growth',\n",
       " 870: 'electricity',\n",
       " 871: 'demand',\n",
       " 872: 'improved',\n",
       " 873: 'operating',\n",
       " 874: 'did',\n",
       " 875: 'come',\n",
       " 876: 'true',\n",
       " 877: 'raising',\n",
       " 878: 'seemed',\n",
       " 879: 'substantial',\n",
       " 880: 'persistent',\n",
       " 881: 'rewards',\n",
       " 882: 'way',\n",
       " 883: 'got',\n",
       " 884: 'hard',\n",
       " 885: 'take',\n",
       " 886: 'added',\n",
       " 887: 'noted',\n",
       " 888: 'political',\n",
       " 889: 'concerns',\n",
       " 890: 'worried',\n",
       " 891: 'matter',\n",
       " 892: 'owns',\n",
       " 893: 'emerges',\n",
       " 894: 'attracts',\n",
       " 895: 'just',\n",
       " 896: 'factors',\n",
       " 897: 'withdraw',\n",
       " 898: 'wilbur',\n",
       " 899: 'ross',\n",
       " 900: 'jr.',\n",
       " 901: 'rothschild',\n",
       " 902: 'adviser',\n",
       " 903: 'troubled',\n",
       " 904: 'holders',\n",
       " 905: 'withdrawal',\n",
       " 906: 'might',\n",
       " 907: 'speed',\n",
       " 908: 'fact',\n",
       " 909: 'increases',\n",
       " 910: 'against',\n",
       " 911: 'around',\n",
       " 912: 'complicated',\n",
       " 913: 'negotiations',\n",
       " 914: 'state',\n",
       " 915: 'asserted',\n",
       " 916: 'field',\n",
       " 917: 'less',\n",
       " 918: 'separately',\n",
       " 919: 'commission',\n",
       " 920: 'turned',\n",
       " 921: 'request',\n",
       " 922: 'seeking',\n",
       " 923: 'possible',\n",
       " 924: 'purchase',\n",
       " 925: 'hopes',\n",
       " 926: 'review',\n",
       " 927: 'ferc',\n",
       " 928: 'summer',\n",
       " 929: 'court',\n",
       " 930: 'shares',\n",
       " 931: 'closed',\n",
       " 932: 'yesterday',\n",
       " 933: 'cents',\n",
       " 934: 'york',\n",
       " 935: 'stock',\n",
       " 936: 'exchange',\n",
       " 937: 'composite',\n",
       " 938: 'trading',\n",
       " 939: 'norman',\n",
       " 940: 'toys',\n",
       " 941: 'r',\n",
       " 942: 'frederick',\n",
       " 943: 'banking',\n",
       " 944: 'directors',\n",
       " 945: 'consumer',\n",
       " 946: 'electronics',\n",
       " 947: 'appliances',\n",
       " 948: 'retailing',\n",
       " 949: 'chain',\n",
       " 950: 'succeed',\n",
       " 951: 'daniel',\n",
       " 952: 'm.',\n",
       " 953: 'retired',\n",
       " 954: 'circuit',\n",
       " 955: 'robert',\n",
       " 956: 'r.',\n",
       " 957: 'undersecretary',\n",
       " 958: 'commonwealth',\n",
       " 959: 'edison',\n",
       " 960: 'ordered',\n",
       " 961: 'refund',\n",
       " 962: 'illegal',\n",
       " 963: 'collected',\n",
       " 964: 'overruns',\n",
       " 965: 'nuclear',\n",
       " 966: 'power',\n",
       " 967: 'illinois',\n",
       " 968: 'commerce',\n",
       " 969: 'groups',\n",
       " 970: 'ever',\n",
       " 971: 'required',\n",
       " 972: 'local',\n",
       " 973: 'utility',\n",
       " 974: 'judge',\n",
       " 975: 'richard',\n",
       " 976: 'curry',\n",
       " 977: 'refunds',\n",
       " 978: 'each',\n",
       " 979: 'customers',\n",
       " 980: 'received',\n",
       " 981: 'april',\n",
       " 982: 'moved',\n",
       " 983: 'begin',\n",
       " 984: 'feb.',\n",
       " 985: 'appeals',\n",
       " 986: 'attempts',\n",
       " 987: 'his',\n",
       " 988: 'order',\n",
       " 989: 'pool',\n",
       " 990: 'through',\n",
       " 991: 'round',\n",
       " 992: 'already',\n",
       " 993: 'appealing',\n",
       " 994: 'underlying',\n",
       " 995: 'considering',\n",
       " 996: 'exact',\n",
       " 997: 'amount',\n",
       " 998: 'determined',\n",
       " 999: 'actual',\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word_to_index['aer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_train = np.array(\n",
    "        [vocab.encode(word) for word in get_ptb_dataset('train')],\n",
    "        dtype=np.int32)\n",
    "encoded_valid = np.array(\n",
    "        [vocab.encode(word) for word in get_ptb_dataset('valid')],\n",
    "        dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929589,)\n",
      "(73760,)\n"
     ]
    }
   ],
   "source": [
    "print encoded_train.shape\n",
    "print encoded_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3, ..., 39,  0, 25], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])\n",
    "b = np.array([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]], [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id = np.array([[1, 2, 3],[1, 2, 3],[1, 2, 3]])\n",
    "m = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = tf.nn.embedding_lookup(a, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1 = b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b2 = b1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 4)\n",
      "(4, 4, 2)\n",
      "(2, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "print b.shape\n",
    "print b1.shape\n",
    "print b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8]],\n",
       "\n",
       "       [[ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8]],\n",
       "\n",
       "       [[ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(b, (4, 2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for ip in xrange(1, 10):\n",
    "    print ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n"
     ]
    }
   ],
   "source": [
    "e = b[0]\n",
    "print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = tf.split(1, 4, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Squeeze_5:0' shape=(4, 4) dtype=int64>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = tf.get_variable(\"v\", initializer = tf.ones([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "x = tf.zeros((2, 3))\n",
    "print x.get_shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(x.get_shape()[0]):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.seq2seq import sequence_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "output = tf.ones([64, 10000])\n",
    "ops = [output, output, output]\n",
    "labels_placeholder = tf.ones([64, 1])\n",
    "labels_placeholder = tf.to_int32(labels_placeholder)\n",
    "lb = [labels_placeholder, labels_placeholder, labels_placeholder]\n",
    "weights = tf.ones([64, 1])\n",
    "we = [weights, weights, weights]\n",
    "# weights = tf.to_int32(weights)\n",
    "print type(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ones_72:0\", shape=(64, 10000), dtype=float32)\n",
      "Tensor(\"ToInt32_25:0\", shape=(64, 1), dtype=int32)\n",
      "Tensor(\"ones_74:0\", shape=(64, 1), dtype=float32)\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print output\n",
    "print labels_placeholder\n",
    "print weights\n",
    "\n",
    "print len(ops)\n",
    "print len(lb)\n",
    "print len(we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype float32 for Tensor with dtype int32: 'Tensor(\"ToInt32_24:0\", shape=(64, 1), dtype=int32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-cb63e766ab0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loss = sequence_loss([output], [labels_placeholder], [weights])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.pyc\u001b[0m in \u001b[0;36msequence_loss\u001b[0;34m(logits, targets, weights, average_across_timesteps, average_across_batch, softmax_loss_function, name)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0maverage_across_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage_across_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m         softmax_loss_function=softmax_loss_function))\n\u001b[0m\u001b[1;32m   1059\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage_across_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.pyc\u001b[0m in \u001b[0;36msequence_loss_by_example\u001b[0;34m(logits, targets, weights, average_across_timesteps, softmax_loss_function, name)\u001b[0m\n\u001b[1;32m   1021\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcrossent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m       \u001b[0mlog_perp_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrossent\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m     \u001b[0mlog_perps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_perp_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage_across_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    581\u001b[0m     raise ValueError(\n\u001b[1;32m    582\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         % (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    584\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype int32: 'Tensor(\"ToInt32_24:0\", shape=(64, 1), dtype=int32)'"
     ]
    }
   ],
   "source": [
    "# loss = sequence_loss([output], [labels_placeholder], [weights])\n",
    "loss = sequence_loss(ops, lb, we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589.46295"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
